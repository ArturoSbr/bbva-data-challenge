{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd0542ef",
   "metadata": {},
   "source": [
    "# Solomaxxing: Data Olympics\n",
    "\n",
    "Este notebook tiene el código para el proyecto de solomaxxing.\n",
    "\n",
    "---\n",
    "\n",
    "Colores corporativos:\n",
    "- #13599B  # Blue\n",
    "\n",
    "-  #2DCCCD  # Aqua\n",
    "\n",
    "- #EE3A6A  # Pink\n",
    "\n",
    "- #F35E61  # Coral"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebd0c3e",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a8accb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Official imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import mutual_info_regression, RFECV, RFE\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Inhouse imports\n",
    "from utils import plot_dual_y\n",
    "\n",
    "# Misc\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5a8c22",
   "metadata": {},
   "source": [
    "Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1b8916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read\n",
    "df = pd.read_csv(os.path.join('..', 'data', 'data_full.csv'))\n",
    "\n",
    "# List of columns\n",
    "cols_og_feats = list(df.columns[1:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512d9644",
   "metadata": {},
   "source": [
    "Set column types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea571710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x-ticks for plots\n",
    "df['fecha_str'] = df['fecha'].str[:7]\n",
    "\n",
    "# Cast fecha to date type\n",
    "df['fecha'] = pd.to_datetime(df['fecha'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec2be3a",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "1. Time features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d105d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base features\n",
    "df = df.assign(\n",
    "    t = np.arange(len(df)),\n",
    "    month = df['fecha'].dt.month,\n",
    "    quarter = df['fecha'].dt.quarter,\n",
    "    year = df['fecha'].dt.year\n",
    ")\n",
    "\n",
    "# From base features\n",
    "df = df.assign(\n",
    "    # Long term\n",
    "    t2 = df['t'].pow(2),\n",
    "    t3 = df['t'].pow(3),\n",
    "    logt = np.log(df['t'] + 1),\n",
    "    # Seasonality\n",
    "    sin_month_1k = np.sin(2 * np.pi * df['month'] / 12),\n",
    "    sin_month_2k = np.sin(2 * np.pi * 2 * df['month'] / 12),\n",
    "    sin_month_3k = np.sin(2 * np.pi * 3 * df['month'] / 12),\n",
    "    cos_month_1k = np.cos(2 * np.pi * df['month'] / 12),\n",
    "    cos_month_2k = np.cos(2 * np.pi * 2 * df['month'] / 12),\n",
    "    cos_month_3k = np.cos(2 * np.pi * 3 * df['month'] / 12),\n",
    "    # Crises\n",
    "    is_post_covid = df['fecha'].ge('2020-04-01').astype(int),\n",
    "    is_post_gfc = df['fecha'].ge('2008-09-01').astype(int)\n",
    ")\n",
    "\n",
    "# Dummies\n",
    "cols_season = ['month', 'quarter']\n",
    "df = pd.concat(\n",
    "    objs=[\n",
    "        df,\n",
    "        pd.get_dummies(df[cols_season], columns=cols_season, dtype=int)\n",
    "    ],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e5a174",
   "metadata": {},
   "source": [
    "2. Lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60b96e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lag all columns\n",
    "lags = [1, 2, 3, 6, 12]\n",
    "_temp = df[cols_og_feats].shift(periods=lags)\n",
    "_temp.columns = [\n",
    "    '_'.join(col.split('_')[:-1]) + '_lag' + col.split('_')[-1]\n",
    "    for col in _temp.columns\n",
    "]  # Add _lagX suffix\n",
    "\n",
    "# Fill nans with most recent value\n",
    "for col in _temp.columns:\n",
    "    col_og = col.split('_lag')[0]\n",
    "    _temp[col] = _temp[col].fillna(df[col_og])\n",
    "df = pd.concat([df, _temp], axis=1)\n",
    "del _temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1651d0",
   "metadata": {},
   "source": [
    "3. Rolling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98018332",
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = [3, 6, 9, 12]\n",
    "\n",
    "# Silly functions\n",
    "funs = ['mean', 'min', 'max', 'std']\n",
    "for window in windows:\n",
    "    _temp = (\n",
    "        df[cols_og_feats]\n",
    "        .rolling(window, min_periods=1, center=False)\n",
    "        .agg(funs)\n",
    "    )\n",
    "    _temp.columns = [f\"{'_'.join(col)}_w{window}\" for col in _temp.columns]\n",
    "\n",
    "    # Declare min/max ratio\n",
    "    for col in cols_og_feats:\n",
    "        _temp[f'{col}_minmax_w{window}'] = _temp[f'{col}_min_w{window}'].div(\n",
    "            _temp[f'{col}_max_w{window}'].replace(0, 0.1)\n",
    "        )\n",
    "        \n",
    "    # Drop min or max (only minmax)\n",
    "    _temp = _temp.drop(\n",
    "        columns=[col for col in _temp.columns if ('_min_w' in col) or ('_max_w' in col)]\n",
    "    )\n",
    "\n",
    "    # Append to df\n",
    "    df = pd.concat([df, _temp], axis=1).fillna(0)\n",
    "\n",
    "# EMAs\n",
    "for span in windows[:2]:\n",
    "    for col in cols_og_feats:\n",
    "        df[f'{col}_ema{span}'] = df[col].ewm(span=span, adjust=False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8857e276",
   "metadata": {},
   "source": [
    "## Bivariate Selection\n",
    "\n",
    "Split data into features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f873089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "feats = cols_og_feats + [\n",
    "    col for col in df.columns if ('_lag' in col) or ('_w' in col) or ('_ema' in col)\n",
    "    or ('_sin' in  col) or ('_cos' in col) or ('is_post_' in col)\n",
    "]\n",
    "mask_train = df['fecha'].lt('2022-05-01')\n",
    "X_train, y_train = df.loc[mask_train, feats], df.loc[mask_train, 'corporativa_mn']\n",
    "X_test, y_test = df.loc[~mask_train, feats], df.loc[~mask_train, 'corporativa_mn']\n",
    "\n",
    "# Mutial info scores\n",
    "mi = mutual_info_regression(X_train, y_train, discrete_features='auto')\n",
    "mi = dict(zip(feats, mi))\n",
    "\n",
    "# Correlations\n",
    "corr = X_train.corr()\n",
    "\n",
    "# Correlation cutoff\n",
    "CORR_CUTOFF = 0.8\n",
    "\n",
    "# For every pair of features with |corr| > CORR_CUTOFF, drop the one with the lowest mutial info coef.\n",
    "biv_drop = set()\n",
    "for i, feat_i in enumerate(feats):\n",
    "    for j, feat_j in enumerate(feats[i + 1:], start=i + 1):\n",
    "        corr_ij = corr.iloc[i, j]\n",
    "        if np.abs(corr_ij) > CORR_CUTOFF:\n",
    "            # Drop feature with lower MI score\n",
    "            if mi[feat_i] < mi[feat_j]:\n",
    "                biv_drop.add(feat_i)\n",
    "            else:\n",
    "                biv_drop.add(feat_j)\n",
    "\n",
    "# Drop biv_cols from all X dataset\n",
    "X_train.drop(columns=biv_drop, inplace=True)\n",
    "X_test.drop(columns=biv_drop, inplace=True)\n",
    "\n",
    "# Print\n",
    "print(f'Dropping {len(biv_drop)} columns using correlations + bivariate comparisons.')\n",
    "print(f'Left with {len(feats) - len(biv_drop)} columns.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbad01c",
   "metadata": {},
   "source": [
    "## Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413153a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params to try\n",
    "grid = {\n",
    "    'n_estimators': [150, 200, 250, 300],\n",
    "    'max_depth': [1, 2, 3],\n",
    "}\n",
    "\n",
    "# CV split\n",
    "tscv = TimeSeriesSplit(n_splits=8)\n",
    "\n",
    "# Init search objects\n",
    "xgb = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    learning_rate=0.01,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "gcv = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=grid,\n",
    "    cv=tscv,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# Fit search\n",
    "gcv.fit(X_train, y_train)\n",
    "\n",
    "# View results\n",
    "res_gcv = pd.DataFrame(gcv.cv_results_)\n",
    "res_gcv = (\n",
    "    res_gcv[\n",
    "        # Parameter cols\n",
    "        [col for col in res_gcv.columns if 'param_' in col]\n",
    "        # Eval cols\n",
    "        + [\n",
    "            'mean_train_score', 'std_train_score', 'mean_test_score', 'std_test_score',\n",
    "            'rank_test_score'\n",
    "        ]\n",
    "    ]\n",
    "    .assign(_score = res_gcv[['mean_test_score', 'std_train_score']].mean(axis=1))\n",
    "    .sort_values('_score', ascending=False)\n",
    ")\n",
    "res_gcv.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4d4565",
   "metadata": {},
   "source": [
    "## Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13447566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init model\n",
    "xgb_tuned = XGBRegressor(\n",
    "    # learning_rate=0.01,\n",
    "    # max_depth=2,\n",
    "    # n_estimators=200,\n",
    "    # subsample=0.8,\n",
    "    # colsample_bytree=0.8,\n",
    "    # random_state=42\n",
    "    **gcv.best_estimator_.get_params()\n",
    ")\n",
    "\n",
    "# Init and fit RFECV\n",
    "rfecv = RFECV(\n",
    "    estimator=xgb_tuned,\n",
    "    step=1,\n",
    "    min_features_to_select=20,\n",
    "    cv=tscv,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "rfecv.fit(X_train, y_train)\n",
    "\n",
    "# View results\n",
    "pd.DataFrame({\n",
    "    'n_features': rfecv.cv_results_['n_features'],\n",
    "    'mean_test_score': rfecv.cv_results_['mean_test_score'],\n",
    "    'std_test_score': rfecv.cv_results_['std_test_score']\n",
    "}).sort_values(by='mean_test_score', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f62aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init and fit RFE\n",
    "rfe = RFE(\n",
    "    estimator=xgb_tuned,\n",
    "    n_features_to_select=21,\n",
    "    step=1\n",
    ")\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# Get results\n",
    "selected_features = X_train.columns[rfe.support_]\n",
    "print(f\"Selected features ({len(selected_features)}):\")\n",
    "print(selected_features.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981afd6c",
   "metadata": {},
   "source": [
    "## Train tuned and pruned regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8220f310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final features\n",
    "feats_final = list(X_train.columns[rfe.support_])\n",
    "\n",
    "# Init and fit model\n",
    "xgb_final = XGBRegressor(**xgb_tuned.get_params())\n",
    "xgb_final.fit(X_train[feats_final], y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_all = xgb_final.predict(df[feats_final])\n",
    "y_pred_test = xgb_final.predict(X_test[feats_final])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b271d57d",
   "metadata": {},
   "source": [
    "Overlaid plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66662b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(\n",
    "    df.loc[mask_train, 'fecha'],\n",
    "    df.loc[mask_train, ['corporativa_mn']],\n",
    "    lw=3,\n",
    "    label='Observed'\n",
    ")\n",
    "plt.plot(df['fecha'], y_pred_all, color='#F35E61', label='Predicted')\n",
    "\n",
    "# Aesthetics\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Saldo (MN)')\n",
    "plt.title('Predicción del saldo de la cartera corporativa')\n",
    "tick_locs = np.arange(0, len(df), 12)\n",
    "tick_labels = df['fecha_str'].iloc[tick_locs]\n",
    "plt.xticks(ticks=df['fecha'].iloc[tick_locs], labels=tick_labels, rotation=45)\n",
    "plt.legend()\n",
    "\n",
    "# Show\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa259a45",
   "metadata": {},
   "source": [
    "Train-test plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84c35df",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df.loc[mask_train, 'fecha'], y_train, label='Observed')\n",
    "plt.plot(df.loc[~mask_train, 'fecha'], y_pred_test, color='#F35E61', label='Forecast')\n",
    "\n",
    "# Aesthetics\n",
    "plt.legend()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Saldo (MN)')\n",
    "plt.title('Predicción del saldo de la cartera corporativa')\n",
    "tick_locs = np.arange(0, len(df), 12)\n",
    "tick_labels = df['fecha_str'].iloc[tick_locs]\n",
    "plt.xticks(ticks=df['fecha'].iloc[tick_locs], labels=tick_labels, rotation=45)\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1ebe47",
   "metadata": {},
   "source": [
    "Final features VS target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c73c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = dict(zip(xgb_final.feature_names_in_, xgb_final.feature_importances_))\n",
    "feats_sorted = sorted(feats_final, key=lambda f: importances.get(f, 0), reverse=True)\n",
    "\n",
    "# Sort according to importance!\n",
    "for col in feats_sorted[:10]:\n",
    "    plot_dual_y(df[mask_train], 'corporativa_mn', col, 'fecha_str')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc97c88",
   "metadata": {},
   "source": [
    "Write preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb92a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pred'] = y_pred_all\n",
    "pred = df.loc[~mask_train, ['fecha', 'pred']].reset_index(drop=True)\n",
    "pred.to_csv(os.path.join('..', 'data', 'pred.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chall",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
